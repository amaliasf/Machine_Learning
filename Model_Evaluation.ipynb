{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluation_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TC2Yo9Zq9IsN",
        "outputId": "4adcc81e-e05f-41c6-8202-3b9f7fdfeff0"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "#import data from url\r\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/haberman.csv'\r\n",
        "list_cols = ['Age', \"Patient's Years\", \"N_positive_ax\", \"survival_status\"]\r\n",
        "df = pd.read_csv(url, names=list_cols)\r\n",
        "\r\n",
        "#melihat 5 data pertama dalam df\r\n",
        "df.head()\r\n",
        "\r\n",
        "#melihat jumlah orang-orang yang positif dan negatif\r\n",
        "df['survival_status'].value_counts()\r\n",
        "\r\n",
        "#splitting data feature and target\r\n",
        "x = df.drop('survival_status', axis=1)\r\n",
        "y = df['survival_status']\r\n",
        "\r\n",
        "#bagi kedua data ini menjadi data training dan data test dengan test_size=0.25.\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "x_train, x_test, y_train,  y_test = train_test_split(x,y, test_size=0.25, random_state=0)\r\n",
        "\r\n",
        "#metric roc_auc saat cross-validation.\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "\r\n",
        "crossval_scores = cross_val_score(LogisticRegression(), x_train, y_train, scoring='roc_auc', cv=10)\r\n",
        "\r\n",
        "#score rata-rata dari model dengan teknik cross-validation\r\n",
        "print(crossval_scores.mean())\r\n",
        "\r\n",
        "#prediksi data test \r\n",
        "model_lr = LogisticRegression()\r\n",
        "model_lr.fit(x_train, y_train)\r\n",
        "y_predict = model_lr.predict(x_test)\r\n",
        "\r\n",
        "#menampilkan hasil prediksi\r\n",
        "y_predict\r\n",
        "\r\n",
        "#hasil confusion matrix\r\n",
        "from sklearn.metrics import confusion_matrix, classification_report\r\n",
        "confusion_matrix(y_test, y_predict)\r\n",
        "\r\n",
        "#classification report dari hasil prediksi\r\n",
        "print(classification_report(y_test, y_predict))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7049019607843137\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.61      0.98      0.75        46\n",
            "           2       0.67      0.06      0.12        31\n",
            "\n",
            "    accuracy                           0.61        77\n",
            "   macro avg       0.64      0.52      0.43        77\n",
            "weighted avg       0.63      0.61      0.50        77\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McMoVRgg9yZ2"
      },
      "source": [
        "Kesimpulan:\r\n",
        "\r\n",
        "Sebagian besar hasil prediksi menunjukkan label 1 (negatif). Hal ini menunjukkan model tidak baik dalam memprediksi pasien yang positif (kelas 2), dan hanya baik dalam memprediksi pasien yang negatif (kelas 1). Hal ini dikarenakan jumlah data yang tidak seimbang (imbalanced) antara pasien, dimana pada data pasien negatif sebanyak 225 dan pasien positif sebanyak 81. Maka model akan cenderung menilai data baru sebagai pasien positif karena model terlalu mempelajari dan mengenali kelas 1, dan kurang mengenali kelas 2. Maka untuk membuat model yang baik, harus diperhatikan bahwa jumlah data antara kategori seimbang."
      ]
    }
  ]
}